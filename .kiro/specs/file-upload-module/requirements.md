# Requirements Document

## Introduction

The File Upload Module provides a backend API and minimal client UI for uploading files to the EduScale Engine. The system supports two storage modes: Google Cloud Storage (GCS) for production cloud deployments and local disk storage for development environments.

The system implements a dual-path upload strategy based on file size:
- **Small files (â‰¤31 MB)**: Direct upload through Cloud Run API with multipart/form-data
- **Large files (>31 MB)**: Two-step process using GCS signed URLs for direct browser-to-storage upload, bypassing Cloud Run's 32 MB request limit

This approach optimizes for simplicity with small files while enabling efficient large file uploads without proxy overhead or Cloud Run limitations.

## Glossary

- **Upload Record**: A record created when a file is uploaded, containing metadata and storage location information
- **Upload Session**: A pre-created upload context for large files that includes a signed URL and metadata, created before the actual file transfer
- **Storage Backend**: The configured destination for uploaded files, either "gcs" (Google Cloud Storage) or "local" (local filesystem)
- **Signed URL**: A time-limited URL generated by GCS that allows direct browser-to-storage uploads without proxying through the API
- **File ID**: A UUID4 identifier generated for each upload session to uniquely identify files
- **Region ID**: A client-provided identifier indicating the geographic or logical region associated with the uploaded data
- **Upload Store**: An in-memory data structure that tracks completed and pending uploads
- **EduScale Engine**: The FastAPI-based backend service that processes educational data
- **Content Type**: The MIME type of the uploaded file (e.g., "text/csv", "audio/mpeg")
- **Upload Method**: The routing strategy for a file upload, either "direct" (through API) or "signed_url" (direct to GCS)

## Requirements

### Requirement 1: Configure Storage Backend

**User Story:** As a system administrator, I want to configure the storage backend for file uploads, so that the same codebase can run in both cloud and local development environments.

#### Acceptance Criteria

1. THE EduScale Engine SHALL read a STORAGE_BACKEND configuration value that accepts "gcs" or "local"
2. WHEN STORAGE_BACKEND is not explicitly set, THE EduScale Engine SHALL default to "local"
3. WHERE STORAGE_BACKEND is "gcs", THE EduScale Engine SHALL require a GCS_BUCKET_NAME configuration value
4. THE EduScale Engine SHALL read a MAX_UPLOAD_MB configuration value that defines the maximum allowed upload size in megabytes
5. THE EduScale Engine SHALL read an ALLOWED_UPLOAD_MIME_TYPES configuration value as a comma-separated list of permitted MIME types

### Requirement 2: Upload Files with Metadata

**User Story:** As a client application, I want to upload a file with metadata in a single request, so that the upload process is simple and efficient.

#### Acceptance Criteria

1. THE EduScale Engine SHALL expose a POST endpoint at /api/v1/upload
2. WHEN a client calls POST /api/v1/upload, THE EduScale Engine SHALL accept multipart/form-data containing a "file" field and a "region_id" field
3. WHEN region_id is empty or missing, THE EduScale Engine SHALL respond with HTTP 400
4. WHEN the file size exceeds MAX_UPLOAD_MB multiplied by 1048576, THE EduScale Engine SHALL respond with HTTP 400
5. WHERE ALLOWED_UPLOAD_MIME_TYPES is configured, WHEN the file content type is not in the allowed list, THE EduScale Engine SHALL respond with HTTP 400
6. WHEN the request is valid, THE EduScale Engine SHALL generate a unique file_id using UUID4
7. WHEN the request is valid, THE EduScale Engine SHALL extract the file name and content type from the uploaded file
8. WHEN the upload is successful, THE EduScale Engine SHALL respond with HTTP 201 and a JSON body containing file_id, file_name, storage_backend, storage_path, and region_id

### Requirement 8: Create Upload Sessions for Large Files

**User Story:** As a client application, I want to create an upload session for large files, so that I can upload files larger than 31 MB directly to GCS without proxying through Cloud Run.

#### Acceptance Criteria

1. THE EduScale Engine SHALL expose a POST endpoint at /api/v1/upload/sessions
2. WHEN a client calls POST /api/v1/upload/sessions, THE EduScale Engine SHALL accept JSON containing region_id, file_name, file_size_bytes, and content_type fields
3. WHEN region_id is empty or missing, THE EduScale Engine SHALL respond with HTTP 400
4. WHEN file_size_bytes exceeds MAX_UPLOAD_MB multiplied by 1048576, THE EduScale Engine SHALL respond with HTTP 400
5. WHERE ALLOWED_UPLOAD_MIME_TYPES is configured, WHEN content_type is not in the allowed list, THE EduScale Engine SHALL respond with HTTP 400
6. WHEN the request is valid, THE EduScale Engine SHALL generate a unique file_id using UUID4
7. WHERE STORAGE_BACKEND is "gcs" AND file_size_bytes is greater than 32505856 bytes, THE EduScale Engine SHALL generate a GCS V4 signed URL for PUT operations
8. THE signed URL SHALL have an expiration time of 15 minutes
9. THE signed URL SHALL include content_type constraint matching the requested content_type
10. THE signed URL SHALL include size constraint matching the requested file_size_bytes
11. WHEN the session is created, THE EduScale Engine SHALL respond with HTTP 201 and JSON containing file_id, upload_method ("direct" or "signed_url"), signed_url (when applicable), target_path, and expires_at
12. WHERE file_size_bytes is less than or equal to 32505856 bytes, THE EduScale Engine SHALL respond with upload_method "direct" and omit signed_url

### Requirement 9: Route Upload Based on File Size

**User Story:** As the system, I want to automatically route uploads based on file size, so that small files use the simple direct upload and large files use signed URLs.

#### Acceptance Criteria

1. THE EduScale Engine SHALL define a threshold of 32505856 bytes (31 MB) for upload routing
2. WHERE STORAGE_BACKEND is "local", WHEN any file is uploaded, THE EduScale Engine SHALL use direct upload through POST /api/v1/upload
3. WHERE STORAGE_BACKEND is "gcs" AND file size is less than or equal to 32505856 bytes, THE EduScale Engine SHALL use direct upload through POST /api/v1/upload
4. WHERE STORAGE_BACKEND is "gcs" AND file size is greater than 32505856 bytes, THE EduScale Engine SHALL require the client to create an upload session via POST /api/v1/upload/sessions
5. WHEN using signed URL upload, THE client SHALL PUT the file directly to the signed_url
6. WHEN the client completes a signed URL upload, THE client SHALL call POST /api/v1/upload/complete with file_id to finalize the upload record

### Requirement 10: Complete Signed URL Uploads

**User Story:** As a client application, I want to finalize an upload after using a signed URL, so that the system records the upload metadata.

#### Acceptance Criteria

1. THE EduScale Engine SHALL expose a POST endpoint at /api/v1/upload/complete
2. WHEN a client calls POST /api/v1/upload/complete, THE EduScale Engine SHALL accept JSON containing file_id
3. WHEN file_id is empty or missing, THE EduScale Engine SHALL respond with HTTP 400
4. WHEN file_id does not exist in the Upload Store, THE EduScale Engine SHALL respond with HTTP 404
5. WHEN the file_id exists AND the file exists in GCS, THE EduScale Engine SHALL update the upload record status to completed
6. WHEN the upload is finalized, THE EduScale Engine SHALL respond with HTTP 200 and JSON containing file_id, file_name, storage_backend, storage_path, region_id, and created_at
7. WHEN the file does not exist in GCS, THE EduScale Engine SHALL respond with HTTP 400

### Requirement 3: Route Files to Storage Backend

**User Story:** As the system, I want to route uploaded files to the appropriate storage backend, so that files are stored correctly based on configuration.

#### Acceptance Criteria

1. WHERE STORAGE_BACKEND is "gcs", WHEN a file is uploaded, THE EduScale Engine SHALL stream the file to GCS at path raw/{file_id}/{sanitized_file_name}
2. WHERE STORAGE_BACKEND is "local", WHEN a file is uploaded, THE EduScale Engine SHALL stream the file to data/uploads/raw/{file_id}/{sanitized_file_name}
3. WHEN the target directory does not exist in local mode, THE EduScale Engine SHALL create the directory structure
4. WHEN streaming the file, THE EduScale Engine SHALL process data in chunks to avoid loading the entire file in memory
5. WHEN the file is successfully stored, THE EduScale Engine SHALL record the upload in the Upload Store with file_id, region_id, file_name, content_type, storage_backend, storage_path, and created_at timestamp
6. WHERE STORAGE_BACKEND is "gcs", WHEN GCS_BUCKET_NAME is not configured, THE EduScale Engine SHALL respond with HTTP 500 and log an error

### Requirement 4: Track Upload Records

**User Story:** As a system administrator, I want upload records to be tracked, so that I can audit and monitor file uploads.

#### Acceptance Criteria

1. THE EduScale Engine SHALL maintain an Upload Store that maps file_id to upload metadata
2. THE Upload Store SHALL store file_id, region_id, file_name, content_type, storage_backend, storage_path, and created_at for each upload
3. WHEN a file upload completes, THE EduScale Engine SHALL add an entry to the Upload Store
4. THE Upload Store SHALL be implemented as an in-memory data structure for the initial implementation
5. THE Upload Store implementation SHALL be modular to allow future replacement with a database backend

### Requirement 5: Provide Upload UI

**User Story:** As a developer or tester, I want a simple web interface for uploading files, so that I can test the upload functionality without writing client code.

#### Acceptance Criteria

1. THE EduScale Engine SHALL expose a GET endpoint at /upload that serves an HTML page
2. THE upload page SHALL include a select input for region_id with predefined options
3. THE upload page SHALL include a file input element
4. THE upload page SHALL include a submit button
5. THE upload page SHALL include a status display area for messages
6. WHEN the user submits the form, THE upload page SHALL call POST /api/v1/upload with multipart/form-data containing the file and region_id
7. THE upload page SHALL display status messages including "Uploading...", "Upload complete", or error messages
8. WHEN the upload succeeds, THE upload page SHALL display the returned file_id and storage information

### Requirement 6: Implement Security Controls

**User Story:** As a security engineer, I want the upload system to validate and sanitize inputs, so that the system is protected from malicious uploads and path traversal attacks.

#### Acceptance Criteria

1. WHEN processing file_name values, THE EduScale Engine SHALL sanitize the name to remove path traversal sequences
2. THE EduScale Engine SHALL store files under a UUID-based directory to prevent path collisions
3. WHEN an upload exceeds configured size limits, THE EduScale Engine SHALL reject the upload with HTTP 400
4. WHEN an upload uses a disallowed MIME type, THE EduScale Engine SHALL reject the upload with HTTP 400
5. THE EduScale Engine SHALL log all completed uploads at info level
6. WHEN errors occur, THE EduScale Engine SHALL log exceptions at error level and return HTTP 500 with a generic error message to clients

### Requirement 7: Support GCS Integration

**User Story:** As a cloud operator, I want the system to integrate with Google Cloud Storage using official client libraries, so that uploads are reliable and follow GCP best practices.

#### Acceptance Criteria

1. THE EduScale Engine SHALL use the google-cloud-storage Python client library for GCS operations
2. THE EduScale Engine SHALL initialize the GCS client once and reuse it across requests
3. THE EduScale Engine SHALL provide a helper function that returns a Bucket object using GCP_PROJECT_ID and GCS_BUCKET_NAME
4. WHEN uploading to GCS, THE EduScale Engine SHALL stream file data in chunks to avoid loading the entire file in memory
5. WHEN uploading to GCS, THE EduScale Engine SHALL set the content_type metadata on the blob
6. THE infrastructure configuration SHALL include a GCS bucket resource for storing uploaded files
7. THE GCS bucket SHALL be configured with appropriate lifecycle policies and access controls


